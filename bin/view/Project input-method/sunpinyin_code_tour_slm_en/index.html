<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
  <head>
                    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
                                    <title>SunPinyin Code Tour - SLM (Project input-method.sunpinyin_code_tour_slm_en) - XWiki</title>
                <meta http-equiv="Content-Script-Type" content="text/javascript" />
                        <meta http-equiv="imagetoolbar" content="no"/>
                      <link rel="alternate" type="application/x-wiki" title="Edit" href="/bin/edit/Project+input%2Dmethod/sunpinyin_code_tour_slm_en" />
                    <link rel="canonical" href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en" />
                            <meta name="document" content="Project input-method.sunpinyin_code_tour_slm_en"/>
    <meta name="wiki" content="xwiki"/>
    <meta name="space" content="Project input-method"/>
    <meta name="page" content="sunpinyin_code_tour_slm_en"/>
    <meta name="version" content="1.1"/>
    <meta name="restURL" content="/rest/wikis/xwiki/spaces/Project+input-method/pages/sunpinyin_code_tour_slm_en"/>
                <meta name="gwt:property" content="locale=en" />
                <meta name="revisit-after" content="7 days" />
<meta name="description" content="SunPinyin Code Tour - SLM" />
<meta name="keywords" content="wiki " />
<meta name="distribution" content="GLOBAL" />
<meta name="rating" content="General" />
<meta name="author" content="admin" />
<meta http-equiv="reply-to" content="" />
<meta name="language" content="en" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<link rel="alternate" type="application/rss+xml" title="Wiki Feed RSS" href="/bin/view/Main/WebRss?xpage=rdf" />
<link rel="alternate" type="application/rss+xml" title="Blog RSS Feed" href="/bin/view/Blog/GlobalBlogRss?xpage=plain" />
<link rel="shortcut icon" href="/resources/icons/oso/icon.png">
                
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
<link href="https://markebrooks.github.io/static/css/stylesheet.css" rel="stylesheet" type="text/css" media="all" />
<link href="/bin/skin/skins/colibri/style.css?colorTheme=ColorThemes.Oso" rel="stylesheet" type="text/css" media="all" />
<link href="/bin/skin/skins/colibri/print.css" rel="stylesheet" type="text/css" media="print" />
        <!--[if IE]>
  <link href="/bin/skin/skins/colibri/ie%2Dall.css" rel="stylesheet" type="text/css" />
<![endif]-->
<!--[if IE 6]>
  <link href="/bin/skin/skins/colibri/ie%2D6.css" rel="stylesheet" type="text/css" />
<![endif]-->
<link rel='stylesheet' type='text/css' href='/bin/ssx/AnnotationCode/Settings?language=en'/><link rel='stylesheet' type='text/css' href='/bin/ssx/AnnotationCode/Style?language=en'/><link rel='stylesheet' type='text/css' href='/bin/ssx/XWiki/SharePage?language=en'/>
<link rel='stylesheet' type='text/css' href='/bin/skin/resources/js/xwiki/widgets/modalPopup.css'/><link rel='stylesheet' type='text/css' href='/bin/skin/resources/js/xwiki/widgets/jumpToPage.css?language=en'/><link rel='stylesheet' type='text/css' href='/bin/skin/resources/uicomponents/widgets/confirmationBox.css'/><link rel='stylesheet' type='text/css' href='/bin/skin/resources/uicomponents/widgets/notification.css'/><link rel='stylesheet' type='text/css' href='/bin/skin/skins/colibri/resources/uicomponents/viewers/tags.css'/>

    
    <link href="/bin/skin/resources/js/xwiki/suggest/ajaxSuggest.css" rel="stylesheet" type="text/css" />
<link href="/bin/skin/resources/js/xwiki/lightbox/lightbox.css" rel="stylesheet" type="text/css" />
<!--[if IE]>
  <link href="/bin/skin/resources/js/xwiki/lightbox/lightboxIE.css" rel="stylesheet" type="text/css" />
<![endif]-->












<script type="text/javascript" src="/resources/js/prototype/prototype.js"></script>
<script type="text/javascript" src="/bin/skin/resources/js/xwiki/xwiki.js"></script>
<script type="text/javascript">
// <![CDATA[
XWiki.webapppath = "";
XWiki.servletpath = "bin/";
XWiki.contextPath = "";
XWiki.mainWiki = "xwiki";
XWiki.currentWiki = "xwiki";
XWiki.currentSpace = "Project input-method";
XWiki.currentPage = "sunpinyin_code_tour_slm_en";
XWiki.editor = "";
XWiki.viewer = "";
XWiki.contextaction = "view";
XWiki.docisnew = false;
XWiki.docsyntax = "xwiki/2.0";
XWiki.blacklistedSpaces = [ "Import","Panels","Scheduler","Stats","XAppClasses","XAppSheets","XAppTemplates","XWiki","WatchCode","WatchSheets","XApp","WatchAdmin","Watch","ColorThemes","AnnotationCode" ];
XWiki.hasEdit = false;
XWiki.hasProgramming = false;
XWiki.hasBackupPackImportRights = false;
window.docviewurl = "/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en";
window.docediturl = "/bin/edit/Project+input%2Dmethod/sunpinyin_code_tour_slm_en";
window.docsaveurl = "/bin/save/Project+input%2Dmethod/sunpinyin_code_tour_slm_en";
window.docgeturl = "/bin/get/Project+input%2Dmethod/sunpinyin_code_tour_slm_en";
// ]]>
</script>
<script type='text/javascript' src='/bin/skin/resources/js/scriptaculous/effects.js' defer='defer'></script>
<script type='text/javascript' src='/bin/skin/resources/js/xwiki/widgets/modalPopup.js' defer='defer'></script>
<script type='text/javascript' src='/bin/skin/resources/js/xwiki/widgets/jumpToPage.js' defer='defer'></script>
<script type='text/javascript' src='/bin/skin/resources/uicomponents/widgets/confirmationBox.js' defer='defer'></script>
<script type='text/javascript' src='/bin/skin/resources/uicomponents/widgets/confirmedAjaxRequest.js' defer='defer'></script>
<script type='text/javascript' src='/bin/skin/resources/uicomponents/widgets/notification.js' defer='defer'></script>
<script type='text/javascript' src='/resources/uicomponents/widgets/list/xlist.js' defer='defer'></script>
<script type='text/javascript' src='/resources/js/xwiki/suggest/ajaxSuggest.js' defer='defer'></script>
<script type='text/javascript' src='/bin/skin/skins/colibri/resources/uicomponents/viewers/tags.js' defer='defer'></script>
<script type='text/javascript' src='/resources/js/scriptaculous/scriptaculous.js' defer='defer'></script>
<script type='text/javascript' src='/resources/js/xwiki/accordion/accordion.js' defer='defer'></script>

<script type='text/javascript' src='/bin/jsx/XWiki/WebDAV?language=en' defer='defer'></script>
<script type='text/javascript' src='/bin/jsx/AnnotationCode/Settings?language=en' defer='defer'></script>
<script type='text/javascript' src='/bin/jsx/AnnotationCode/Script?language=en' defer='defer'></script>

<script type="text/javascript" src="/resources/js/xwiki/compatibility.js" defer="defer"></script>

  </head>
  <body id="body" class="wiki-xwiki space-Project_input-method viewbody hideright">
<div id="xwikimaincontainer">
<div id="xwikimaincontainerinner">

  <div id="menuview">
    <div id="mainmenu" class="layoutsubsection actionmenu">
<strong id="xwikimenutitle" class="hidden">General Actions:</strong>
<div class="rightmenu">
      <div id="tmLogin" class="tmLogin topmenuentry ">
   <a class="tme" href="https://auth.opensolaris.org/login.action?targetUrl=http%3A%2F%2Fmarkebrooks.github.io%2Fbin%2Fview%2FProject%2Binput%252Dmethod%2Fsunpinyin_code_tour_slm_en"><strong>Log-in</strong></a>
  </div>
  </div>
<div class="leftmenu">
  <div id="tmWiki" class="tmWiki topmenuentry hasIcon">
   <a class="tme" href="/bin/view/Main/"><strong>Wiki</strong></a>
  </div>
  <div id="tmSpace" class="tmSpace topmenuentry dropdownmenuentry  hasIcon" onmouseover="showsubmenu(this);" onmouseout="hidesubmenu(this);">
<span class="tme-extensible">
   <a class="tme" href="/bin/view/Project+input%2Dmethod/"><strong>Project input-method</strong></a>
    <span class="hidden menucolon">: </span>
</span><span class="submenu hidden">
                <span class="submenuitem "><a href="/bin/view/Main/SpaceIndex?space=Project+input%2Dmethod" id="tmSpaceDocumentIndex" class="tmSpaceDocumentIndex">Document Index</a></span>
    </span></div>

<div id="tmSubSites" class="tmSubSites topmenuentry dropdownmenuentry dropdownnolink hasIcon" onmouseover="showsubmenu(this);" onmouseout="hidesubmenu(this);">
<span class="tme-extensible">
   <a class="tme"><strong>Subsites</strong></a>
    <span class="hidden menucolon">: </span>
</span><span class="submenu hidden">
<span class="submenuitem hasIcon"><a href="https://cr.opensolaris.org/" id="tmCR" class="tmCR">Code Reviews</a></span>
<span class="submenuitem hasIcon"><a href="http://repo.opensolaris.org/" id="tmRepo" class="tmRepo">SCM Management</a></span>
<span class="submenuitem hasIcon"><a href="http://pkg.opensolaris.org/" id="tmPkg" class="tmPkg">Package Search</a></span>
<span class="submenuitem hasIcon"><a href="http://bugs.opensolaris.org/" id="tmBugs" class="tmBugs">Bugster</a></span>
<span class="submenuitem hasIcon"><a href="http://defect.opensolaris.org/" id="tmDefect" class="tmDefect">Bugzilla</a></span>
<span class="submenuitem hasIcon"><a href="http://test.opensolaris.org/" id="tmTest" class="tmTest">Test Machines</a></span>
<span class="submenuitem hasIcon"><a href="http://planet.opensolaris.org/" id="tmPlanet" class="tmPlanet">Planet</a></span>
<span class="submenuitem hasIcon"><a href="http://mail.opensolaris.org/" id="tmMail" class="tmMail">Mailing Lists</a></span>
<span class="submenuitem hasIcon"><a href="http://poll.opensolaris.org/" id="tmPoll" class="tmPoll">Elections &amp; Polls</a></span>
<span class="submenuitem hasIcon"><a href="http://arc.opensolaris.org/" id="tmArc" class="tmArc">ARC Case Logs</a></span>
<span class="submenuitem hasIcon"><a href="http://jucr.opensolaris.org/" id="tmJucr" class="tmJucr">Source Juicer</a></span>
<span class="submenuitem hasIcon"><a href="http://pkgfactory.opensolaris.org/" id="tmPkgfactory" class="tmPkgfactory">Package Factory</a></span>
<span class="submenuitem hasIcon"><a href="http://auth.opensolaris.org/" id="tmAuth" class="tmAuth">Auth</a></span>
</span></div>

</div>
</div>

  </div>
 <div id="header" class="layoutsection">
<div class="minwidthb"></div>

  <div id="header">
    <table style="width: 100%;">
        <tr>
            <td style="width: 1%;">
                 <a href="https://markebrooks.github.io/bin/view/Main/"><div id="logo"></div></a>  
            </td>
            <td id="logo-text" style="width: 1%;">
                Solaris
            </td>         
            <td style="width: 98%;">
                <table id="loading-indicator">
                    <tr>
                        <td><img src="https://markebrooks.github.io:443/static/images/busy.gif"
                                 alt="Loading" title="Loading"/></td>
                        <td>Loading...</td>
                    </tr>
                </table>
            </td>
            <td style="width: 1%;">
                <table id="iconbar">
                    <tr>
                    <td><a id="collectives-icon" href="https://markebrooks.github.io/bin/view/Main/collectives">
                        Collectives</a></td>
                    <td><a id="discussions-icon" href="https://markebrooks.github.io/bin/view/Main/discussions">
                            Discussions</a></td>
                    <td><a id="documentation-icon" href="https://markebrooks.github.io/bin/view/Main/documentation">
                            Documentation</a></td>
                    <td><a id="download-icon" href="https://markebrooks.github.io/bin/view/Main/downloads">
                            Download</a></td>
                    <td><a id="source-browser-icon" href="http://src.opensolaris.org/source">
                            Source Browser</a></td>
                    </tr>
                </table>
            </td>
        </tr>
    </table>
</div>

 </div> 
  <div id="globallinks">
    <form action="/bin/view/Main/Search">
      <div class="globalsearch">
        <label class="hidden" for="headerglobalsearchinput">Search</label><input class="globalsearchinput withTip" id="headerglobalsearchinput" type="text" name="text" value="search..." size="15"/><input class="button" type="image" value="Go" alt="Go" src="/resources/icons/xwiki/search.png"/>
      </div>
    </form>
  </div> <div style="float:left;">

                

   <div id="hierarchy">
                              <a href='/bin/view/Project+input%2Dmethod/documents'>Documents</a> <span class='separator'>&#187;</span> <span class='current'>SunPinyin Code Tour - SLM</span>
                </div>

</div>
  <span class="glink" id="headerlanguages" style="float:right">
        <a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?language=en" class="language-default language-current">en</a>
    </span>


<div class="contenthideright" id="contentcontainer">
<div id="contentcontainerinner">
<div class="leftsidecolumns">
  <div id="contentcolumn"> 
          <div class="main layoutsubsection">
      <div id="contentmenu" class="actionmenu">
    <strong id="xwikicontentmenutitle" class="hidden">Page Actions:</strong>
<div class="rightmenu">
</div>
<div class="leftmenu">
  <div id="tmExport" class="tmExport topmenuentry dropdownmenuentry dropdownnolink " onmouseover="showsubmenu(this);" onmouseout="hidesubmenu(this);">
<span class="tme-extensible">
   <a class="tme"><strong>Export</strong></a>
    <span class="hidden menucolon">: </span>
</span><span class="submenu hidden">
  <span class="submenuitem "><a href="/bin/export/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?format=pdf&amp;language=en" id="tmExportPdf" class="tmExportPdf">Export as PDF</a></span>
  <span class="submenuitem "><a href="/bin/export/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?format=rtf&amp;language=en" id="tmExportRtf" class="tmExportRtf">Export as RTF</a></span>
  <span class="submenuitem "><a href="/bin/export/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?format=html&amp;language=en" id="tmExportHtml" class="tmExportHtml">Export as HTML</a></span>
    </span></div>

<div id="tmShow" class="tmShow topmenuentry dropdownmenuentry  " onmouseover="showsubmenu(this);" onmouseout="hidesubmenu(this);">
<span class="tme-extensible">
   <a class="tme" href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?viewer=code&amp;language=en"><strong>View</strong></a>
    <span class="hidden menucolon">: </span>
</span><span class="submenu hidden">
<span class="submenuitem "><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?viewer=comments&amp;language=en" id="tmViewComments" class="tmViewComments">Comments</a></span>
<span class="submenuitem "><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?viewer=attachments&amp;language=en" id="tmViewAttachments" class="tmViewAttachments">Attachments</a></span>
<span class="submenuitem "><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?viewer=history&amp;language=en" id="tmViewHistory" class="tmViewHistory">History</a></span>
<span class="submenuitem "><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?viewer=information&amp;language=en" id="tmViewInformation" class="tmViewInformation">Information</a></span>
<span class="submenuitem "><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?viewer=code&amp;language=en" id="tmViewSource" class="tmViewSource">View Source</a></span>
</span></div>

  <div id="tmMoreActions" class="tmMoreActions topmenuentry dropdownmenuentry dropdownnolink " onmouseover="showsubmenu(this);" onmouseout="hidesubmenu(this);">
<span class="tme-extensible">
   <a class="tme"><strong>More actions</strong></a>
    <span class="hidden menucolon">: </span>
</span><span class="submenu hidden">
  <span class="submenuitem "><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?xpage=print&amp;language=en" id="tmPrintPreview" class="tmPrintPreview">Print preview</a></span>
          <span class="submenuitem "><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en?xpage=copy" id="tmActionCopy" class="tmActionCopy">Copy</a></span>
      </span></div>
</div>

    </div>
    <div id="mainContentArea">
      








    
<div id="document-title"><h1>SunPinyin Code Tour - SLM</h1></div>



    <strong>NOTE: The
 input-method project
 is no longer active on this website so information here may be out of date. Current Oracle Solaris 11 product documentation can be found </strong>
  <strong><a href="http://www.oracle.com/technetwork/server-storage/solaris11/documentation/index.html">here</a>.</strong>
  <strong>Information about downloading Oracle Solaris 11 can be found <a href="http://www.oracle.com/technetwork/server-storage/solaris11/downloads/index.html">here</a>.</strong>
<hr>
  


              <div id="document-info">
    <div>
          </div>
    <div class="clearfloats"></div>
  </div>

<div id="xwikicontent">
<h2 id="H0.Overview"><span>0. Overview</span></h2><p>&nbsp;At first, let's check out the sources from inputmethod repository,<br/>&nbsp;$ hg clone <span class="wikiexternallink"><a class="wikimodel-freestanding" href="ssh://anon//@//hg.opensolaris.org/hg/nv-g11n/inputmethod"><span class="wikigeneratedlinkcontent">ssh://anon//@//hg.opensolaris.org/hg/nv-g11n/inputmethod</span></a></span><br/>&nbsp;Or you could navigate to the <span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/">input-method</a></span> project on <span class="wikiexternallink"><a href="http://www.opensolaris.org">www.opensolaris.org</a></span>, and download the <span class="wikiexternallink"><a href="https://markebrooks.github.io/bin/download/Project+input-method/files/inputmethod-repo-snapshot.tar.gz">latest repository snapshot</a></span>. (While it does not include the large binary data files in ime/data, you could download them from <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/ime/data/">here</a></span>.)<br/>&nbsp;SunPinyin's source is located under inputmethod/sunpinyin, which contains two parts: the sources under slm directory are the training utilities for statistical language model; the ones under ime are related to input method engine usage, including the core logic and various portings for different input method frameworks.<br/>&nbsp;The code in slm directory is used to build a back-off based n-gram statistical language model,<br/>&nbsp;You could build the utilities as following steps:<br/>&nbsp;$ ./autogen.sh --prefix=/usr<br/>&nbsp;$ make<br/>&nbsp;build: all compiled utilities (as their object files) are located in this directory, e.g., ids2ngram, slmbuild etc. By checking the Makefile.am in this folder, you could know how to build the slm and lexicon files step by step.<br/>&nbsp;$ export LC_ALL=zh_CN.UTF-8<br/>&nbsp;Since the dictionaries and raw corpus are in UTF-8 encoding, so please set your locale to any UTF-8 locale before we proceed.<br/>&nbsp;$ make test_corpus (or real_corpus)<br/>&nbsp;This target is to create a symbol link to corpus.utf8. You could manually create it.<br/>&nbsp;$ make trigram<br/>&nbsp;This target is to produce a trigram language model.</p><ol><li>Use mmseg (the forward maximum matching segmenting), to tokenize the raw corpus basing the dictionary, and output the word IDs to a file (../swap/lm_sc.ids).</li><li>Use ids2ngram to calculate all recurrences for every trigram, and output the result to a file. Take the following sentence as an example, 'ABCEBCA。', the trigrams we could get are (&lt;S&gt; A B), (A B C), (B C E) ... ( B C A), (C A 。), (A '。' &lt;/S&gt;). (&lt;S&gt; and &lt;/S&gt; stand for start and end of sentence separately.)</li><li>Use slmbuild to construct a back-off trigram language model, but not pruned yet.</li><li>Use slmprune to prune the trigram model, with an Entropy-based algorithm.</li><li>Use slmthread to thread the language model, to speed up the locating of back-off states. And save the final output to ../data/lm_sc.t3g。</li></ol><p>&nbsp;$ make bs_trigram<br/>&nbsp;This target is similar with the above one, the only difference is it use slmseg to do the segmentation, it utilizes the language model we just got (segmented by FMM), to re-segment the raw corpus. That could improve the accuracy of language model.<br/>&nbsp;$ make lexicon<br/>&nbsp;According to the unigram information in the generated language model, process the dictionary file, and get a lexicon file (a trie indexed by pinyin characters) that supports incomplete pinyin.<br/>&nbsp;We will introduce the code details later.</p><h2 id="H1.DictionaryandWordSegmentation"><span>1. Dictionary and Word Segmentation</span></h2><p>&nbsp;As we described previously, Sunpinyin uses FMM (forward maximum matching) for the 1 pass word segmentation. The dictionary are loaded to a trie structure, the key is the Chinese character in UCS-4. Some nodes come into valid words, e.g., on the most left path in following diagram, "中国" is a valid word; while on the path of "中华人民共和国", the node "共" could not stands for a valid word. (This structure is similar with the one in <span class="wikiexternallink"><a href="http://xiecc.itpub.net/post/1476/52479">reference 3</a></span>.)<br/>&nbsp;We could see, all child nodes of root are valid words, since every character could be considered as "single character word".<br/><img src="http://blogs.sun.com/yongsun/resource/dict_trie.png" alt="http://blogs.sun.com/yongsun/resource/dict_trie.png"/><br/><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_dict.h">sim_dict.[h</a></span>|<span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_dict.cpp">cpp</a></span>]:</p><blockquote><p> <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_dict.cpp#66">parseText</a></span> ()   : load the dictionary in text file, and construct a trie.</p></blockquote><p><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_dict.cpp#51">matchLongest</a></span> (): to do the longest match, and return the length.<br/><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_dict.cpp#41">step</a></span> ()        : by given a character, transfer to a child node, and return it.</p><p><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/mmseg/mmseg.cpp">mmseg/mmseg.cpp</a></span>:</p><blockquote><p>&nbsp;&nbsp;In function <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/mmseg/mmseg.cpp">processSingleFile</a></span>(), read the corpus sentence by sentence. For example, "为人民办实事的精神", and then call <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_dict.cpp#51">SIMDict::matchLongest</a></span>() to do the longest match.</p></blockquote><p>&nbsp;Because there is the entry "为人民" in dictionary，so the 1st segmented word we got is "为人民"，its length is 3, then call <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/mmseg/mmseg.cpp#173">getAmbiLen</a></span>() to see if there are crossing-ambiguities, and return the maximum length of crossing-ambiguities. The following is the result for each iteration：</p><ol><li>人民, 办实事的精神 -&gt; i=1, len=2, word_len=3, do FMM for "人民办实事", get the matched word "人民", its length is 2.</li><li>民办, 实事的精神 -&gt; i=2, len=2, word_len=4, do FMM for "民办实事"，get the matched word "民办"，its length is 2. Since the i+len is longer than the original parameter word_len, set the word_len to i+len (ie. 4), continue the iteration. You could see, we have detect the ambiguity.</li><li>办实事, 的精神 -&gt; i=3, len=3, word_len=6</li><li>实事, 的精神 -&gt; i=4, len=2, word_len=6</li><li>事, 的精神 -&gt; i=5, len=1, word_len=6, the ambiguity length is now determined as 6.</li><li>break the loop, and return the ambiguity length, ie. 6 If an ambiguous-id is specified (by the option -a), these 6 characters would be ignored, and output the specified AMBI-ID to the result, then continue the processing. When reach the end of a sentence, if we require the binary output format, a sentence ending ID (specified by option -s) would be <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/mmseg/mmseg.cpp#231">output</a></span>. Here shows a result in text format:<br/>&nbsp;$ echo "为人民办实事的精神" | ./mmseg -d ../raw/dict.utf8 -f text -s 10  -a 9<br/>&nbsp;&lt;ambi&gt;为人民办实事&lt;/ambi&gt; 的 精神</li></ol><p>&nbsp;So, in our segmentation result, all crossing-ambiguities are marked as single one word ID (AMBI-ID). That means we ignored that part of information (the ratio is considerable). Thus in our later processing, most of the trigrams are meaningful and valuable. The language model we got, could avoid the cross-ambiguities' impact somehow. Then, useslmseg on this language model, to re-segment the raw corpus and get the new language model. This time, the original ambigious information is also leveraged.<br/>&nbsp;$ echo "为人民办实事的精神" | ./slmseg -d ../raw/dict.utf8 -f text -s 10 -m ../data/lm_sc.t3g<br/>&nbsp;为人民 办实事 的 精神<br/>&nbsp;Note, dueto the copyright of raw corpus, we may not be able to open it, however, to use slmseg, you could create a symbol link to ime/data/lm_sc.t3g.&lt;arch&gt; in slm/data directory.<br/>&nbsp;References:</p><ol><li><span class="wikiexternallink"><a href="http://googlechinablog.com/2006/04/blog-post_10.html">数学之美 系列二 <del>&nbsp;谈谈中文分词</del></a></span></li><li><span class="wikiexternallink"><a href="http://www.stlchina.org/twiki/bin/view.pl/Main/SESegment">中文搜索引擎技术揭密：中文分词</a></span></li><li><span class="wikiexternallink"><a href="http://xiecc.itpub.net/post/1476/52479">“天堂的阶梯”设计的中文分词算法</a></span></li></ol><h2 id="H2.CountingTrigrams"><span>2. Counting Trigrams</span></h2><p>&nbsp;After we tokenized the corpus, the task is to count the occurrence numbers of each trigram:<br/><span class="box code">$ make m3_idngram<br/> <span style="color: #666666; ">./</span>ids2ngram <span style="color: #666666; ">-</span>n 3 <span style="color: #666666; ">-</span>s .<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>swap <span style="color: #666666; ">-</span>o .<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.id3gram <span style="color: #666666; ">-</span>p 5000000 .<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.ids</span><br/><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/ids2ngram/ids2ngram.cpp">ids2ngram.cpp</a></span>：<br/><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/ids2ngram/ids2ngram.cpp#59">ProcessingRead</a></span>()</strong>：</p><blockquote><p>&nbsp;&nbsp;Read the ID stream file generated in previous step. Read N-1 (in trigram case, it's 2) IDs firstly, save to the ids array (a member inngram object). Then read another ID, save it as the third element (.e., ids[N-1]) in ids array. Invoke the operator [] of std::map, by using array ids[0..2] as the key, retrieve the occurrence number for this trigram, (if never seen in the map, operator [] will insert the &lt;key,0&gt; pair to map), increase the number. Shift the ids array to left by one cell, continue the above processing.</p></blockquote><p>&nbsp;In the iterations, we also monitor if the size of map reaches the maximum number (paraMax). It's to prevent the map from occupying too much memory space. If reaches the maximum number, output the map to a swap file, record the offset for this paragraph, then clear the map, continue the counting. Note, the std::map is an ordered container, the inner structure is a balanced-ordered-binary-tree (usually is a red-black tree). We then need perform a merge sort for all paragraphs.</p><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/ids2ngram/idngram_merge.h#65">ProcessingIdngramMerge</a></span>()</strong>：</p><blockquote><p>&nbsp;&nbsp;Merging sort. To perform a merging sort for several ordered data sources, is to find the minimal (or maximum) one in the head elements and output it, then the head of the affected data source moves to its next element, repeat the above processing, till the set of head elements is empty. If we have many data sources to be sorted, sorting the head elements becomes a critical step for performance. InSunPinyin, there is a template class to deal the multiple-way merging, i.e., <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_fmerge.h">slm/sim_fmerge.h</a></span>. It uses the heap sorting algorithm to sort the head elements. <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_fmerge.h#130">getBest</a></span>() returns the paragraph who has the minimal head element, <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_fmerge.h#135">next</a></span>() adds the next element in this paragraph to heap.</p></blockquote><p>&nbsp;Finally, we got a raw trigram model without any smoothing, i.e., all trigrams with their occurrence numbers.</p><h2 id="H3.Buildtheback-offbasedn-gramlanguagemodel"><span>3. Build the back-off based n-gram language model</span></h2><p>&nbsp;Next step is to build a back-off based n-gram model:<br/><span class="box code">$ make m3_slm<br/> <span style="color: #666666; ">./</span>slmbuild <span style="color: #666666; ">-</span>n 3 <span style="color: #666666; ">-</span>o .<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.3gram  <span style="color: #666666; ">-</span>w 120000 <span style="color: #666666; ">-</span>c 0,2,2 <span style="color: #666666; ">-</span>d ABS,0.0005 <span style="color: #666666; ">-</span>d ABS <span style="color: #666666; ">-</span>d ABS,0.6 <span style="color: #666666; ">-</span>b 10 <span style="color: #666666; ">-</span>e 9 .<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.id3gram</span><br/>&nbsp;Firstly, let's have a look at the definition of n-gram.<br/>&nbsp;For the statistical based NLP (natural language processing), the probability of a sentence (S=W1,W2,...Wn), according to the chain rule, is:<br/><span class="box code">P(S) = P(W1).P(W2<span style="color: #666666; ">|</span>W1).P(W3<span style="color: #666666; ">|</span>W1,W2).P(W4<span style="color: #666666; ">|</span>W1,W2,W3)...P(Wn<span style="color: #666666; ">|</span>W1,W2,...Wn<span style="color: #666666; ">-</span>1)<br/>&nbsp;     = P(W1).prod_i^n (P(Wi<span style="color: #666666; ">|</span>W1,W2,...Wi<span style="color: #666666; ">-</span>1))</span><br/>&nbsp;To express mathematics equations in text mode, we use Latex-like language here. To express the above equation with Latex, it's P(S) = P(W_1)\prod_i^nP(W_i|W_1,W_2,...W_{i-1}), the visualizing form is:</p><blockquote><p> <img src="http://www.sitmo.com/latex/latex2png.php?eq=P%28S%29%20=%20P%28W_1%29%5Cprod_i%5EnP%28W_i%7CW_1,W_2,...W_%7Bi-1%7D%29" alt="http://www.sitmo.com/latex/latex2png.php?eq=P%28S%29%20=%20P%28W_1%29%5Cprod_i%5EnP%28W_i%7CW_1,W_2,...W_%7Bi-1%7D%29"/></p></blockquote><p>&nbsp;While in reality, due to the data sparseness, it's impossible to calculate the probability in such a way. A particle method is, to assume the P(Wi|W1,W2,...Wi-1) only depends on the previous N words, i.e., Wi-N+1,Wi-N+2,...Wi-1. In particular, we have unigram (N=0，context-free grammar), bigram (N=1), trigram (N=2), and fourgram (N=3). The most commonly used is trigram.<br/>&nbsp;Let's have a look at several useful terms:</p><ul><li>types: the size of vocabulary (or dictionary)</li><li>tokens: the size of corpus</li><li>vector/solution space: for a N-gram model, V = types^N</li><li>data sparseness: tokens &lt;&lt; V, tokens is much smaller than V</li><li>Maximum likelihood: Pml(Wi|Wi-2,Wi-1) = C(Wi-2,Wi-1,Wi)/C(Wi-2,Wi-1), C stands for the occurrence numbers. This means the maximum likelihood estimation of P(Wi|Wi-2,Wi-1) equals to the ratio of occurrence numbers of (Wi-2,Wi-1,Wi) and (Wi-2,Wi-1).</li></ul><p>&nbsp;Many possible word sequences, may not be collected in the training corpus. If Pml(Wi|h) is 0, then the probability of entire sentence becomes 0. E.g., if we only see "Tom read a book" in corpus, while we don't see anything like "Yong read xxx", then Pml(Yong read a book) = 0. So, we need to smooth the model. Smoothing is to allocate some probabilities from known events to unknown events (i.e., the events whose occurrence number is 0).<br/>&nbsp;Some smoothing methodologies：</p><ul><li>Simple Smoothing: add-one (or add delta), poor performance if used alone</li><li>Discounting smoothing: E.g., Absolute Discounting, liner smoothing, Witten-Bell, Good-Turing</li><li>Composite smoothing: back-off smoothing, and interpolated smoothing</li></ul><p>&nbsp;A general back-off model could be expressed as following:<br/><span class="box code">Ps(Wi<span style="color: #666666; ">|</span>h) = Pd(Wi<span style="color: #666666; ">|</span>h)         <span style="color: #666666; ">~--</span> C(h,Wi) <span style="color: #666666; ">&gt;</span> 0<br/>&nbsp;           bow(h).Ps(Wi<span style="color: #666666; ">|</span>h<span style="color: #666666; ">'</span>) <span style="color: #666666; ">~--</span> C(h,Wi) <span style="color: #666666; ">==</span> 0</span></p><ul><li>h' is the history h truncated by the first word. For trigram (A,B,Wi), h is (A,B), so h' is B.</li><li>Pd(Wi|h) &lt; Pml(Wi|h), to discount the ML estimation, many discounting methods could be used</li><li>bow(h) is the back-off weight, to a given h, bow(h) is a <strong>const number</strong>, and could be determined by Ps(W1|h)+Ps(W2|h)+...+Ps(Wn|h) = sum_i (Ps(Wi|h)) = 1</li><li>this is a recursive expression, if the occurrence number of (h',Wi) is 0, then back-off continues, it may back-off to Wi, even to a average distribution (if Wi is not seen).</li><li>if h is not seen in training stage, P(Wi|h) = P(Wi|h')</li></ul><p>&nbsp;Katz's back-off model used Good-Turing. Kneser-Ney is another back-off model, whose performance is better than Katz's model. Stanley Chen and Joshua Goodman once wrote a <span class="wikiexternallink"><a href="http://www.cs.cmu.edu/%7Esfc/papers/h015a-techreport.ps.gz">thesis</a></span>, discussed the pros and cons of different smoothing methods, you could refer to it for more details.<br/>&nbsp;Let's look at the code.<br/><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.h">sim_slmbuilder.[h</a></span>|<span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp">cpp</a></span>]：<br/><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#96">CSlmBuilder::Create</a></span>(n)</strong>：</p><blockquote><p>&nbsp;&nbsp;To initialize the level array according to parameter n, level[0] is pseudo root, used for average distribution. level[1] is forunigram，level[2] is for bigram , and level[3] is for trigram... For trigram, the nodes on level[3] are leaf nodes. The leaf nodes do not have bow information, since they belong to circumstances that C(h,Wi)&gt;0.</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#160">CSlmBuilder::AddNGram</a></span>(ngram, fr)</strong>：</p><blockquote><p>&nbsp;&nbsp;Call isExcludeId() to check if the first word of ngram is an excluded word (in this case it's 9, the AMBI-ID). For every vector in array level[1..n], check if its reserved space is used up, if true, allocate more memory for it. If the 1st word is not a excluded word, add its occurrence number to level[0][0] (i.e., pseudo root). Add each word id inngram to level[i] (0&lt;i&lt;=n), and accumulate the occurrence number in parent node. For level[n] (i.e., the leaf level), only the ngram whose occurrence number is bigger than the specified cut number, would be added; it's to avoid the leaf node numbers are too high (maybe tens of millions), so that we could not save them in memory.</p></blockquote><p>&nbsp;In this function, we check, if ngram[i] (0&lt;i&lt;=n-1) is an excluded word, then only the ngram[0..i-1] would be counted; if ngram[i] (0&lt;=i&lt;=n-1) is a sentence stop (as we specified, it's 10), then only ngram[0..i] is counted. E.g., for trigram (9, x, y), it's ignored directly; for (x, 9, y), only unigram <img src="/resources/icons/silk/cancel.gif" class="wikimodel-freestanding" alt="cancel"/>&nbsp;is counted; for (10, x, y), unigram (10) is counted; for (x, 10, y), unigram <img src="/resources/icons/silk/cancel.gif" class="wikimodel-freestanding" alt="cancel"/>&nbsp;and bigram (x, 10) are counted.</p><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#486">CSlmBuilder::Build</a></span>()</strong>：</p><blockquote><p>&nbsp;&nbsp;The entry point to build the back-off based n-gram model.</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#209">CSlmBuilder::CountNr</a></span>()</strong>：</p><blockquote><p>&nbsp;&nbsp;Counting the total occurrence numbers of ngrams whose occurence number is less than SLM_MAX_R (i.e., 16). E.g., nr[3][0] is the tatal number of trigrams, nr[3][10] is the total occurrence numbers for the trigrams which occurs 10 times (can only be times of 10, e.g., 500). These data would be used when initializing discounters.</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#299">CSlmBuilder::AppendTails</a></span>()</strong>：</p><blockquote><p>&nbsp;&nbsp;To add a tail node for each level, just for convenience in iterating.</p></blockquote><p><img src="http://blogs.sun.com/yongsun/resource/backoff-trigram-data-structure.png" alt="http://blogs.sun.com/yongsun/resource/backoff-trigram-data-structure.png"/><br/><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#276">CSlmBuilder::Cut</a></span>()</strong>：</p><blockquote><p>&nbsp;&nbsp;Delete the ngrams whose occurrence number is less than specified threshold. The thresholds we specified is (-c 0,2,2), which means we will ignore thebigrams and trigrams whose occurrence number is less than 2, but do not cut any unigrams.</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#337">CSlmBuilder::Discount</a></span>()</strong>：</p><blockquote><p>&nbsp;&nbsp;Initialize the discounter for each level. Call DiscountOneLevel() to perform discounting for each level, from higher to lower. And set the level[0] (pseudo root) as average distribution, its probability is 1 divided by the number of types (specified by -w flag, in this example is 120000).</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#317">CSlmBuilder::DiscountOneLevel</a></span>(v, ch, disc ...)</strong>：</p><blockquote><p>&nbsp;&nbsp;v is the previous level, e.g., if we are discounting level[3], then the 1st argument is level[2]. To discount level[m], iterate every node in level[m-1], then discount its child nodes ([it-&gt;child,itnext -&gt;child)). The number subtracted here are frequencies, not probabilities. Then divided by the frequency in parent node, get the conditional probability, save it in the original node.</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#395">CSlmBuilder::CalcBOW</a></span>()</strong>：</p><blockquote><p>&nbsp;&nbsp;Calculate back-off weights, from higher to lower level. base[i] refers to the 1st element in level[i], idx[i] is the cursor in level[i], so (base[i])[idx[i]) is the visiting node. (Here we rely on the fact that the memory space allocated in std::vector is continuous, we could use pointer or array to access the elements.)</p></blockquote><blockquote><p>&nbsp;&nbsp;Take calculating BOWs on level[2] as an example. Then, lvl is 2, and we are going to iterate every word in base[2]. At first, try to find the parent node for this word with a for loop, .e.g,idx [2] refers to the level[2][1] (C) in above diagram, then its parent is level[1][0] (A), put them in the word[0..4] array, as a result it's {0, A, C, .}. Then callCalcNodeBow () to get the BOW for this node, the last two parameters in this function, is the range of children nodes [ch+node.child, ch+nodenext.child).</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/sim_slmbuilder.cpp#367">CalcNodeBow</a></span>(...)</strong>：</p><blockquote><p>&nbsp;&nbsp;Iterate the node in [chh, cht), accumulate every probability to variable sumnext; and call builder-&gt;getPr(lvl, words+2) to get a probability, accumulate to variable sum. The actual effect of words+2, is to truncate the 1st word in history. Use above example, on the 1st iteration, words[0.4]={0, A, C, D}, so words+2 is {C, D}, the probability returned bygetPr() is P s(D|C) (Note, getPr() itself is a recursive function, when lvl is 0, return the average distribution probability). BOW is then calculated as (1.0-sumnext)/(1.0-sum).</p></blockquote><blockquote><p>&nbsp;&nbsp;As we explained, BOW is determined by equation sum_i (Ps(Wi|h)) = 1. From the following transformation, you could see the meanings of sumnext and sum.</p></blockquote><p><img src="http://blogs.sun.com/yongsun/resource/bow-calculation.png" alt="http://blogs.sun.com/yongsun/resource/bow-calculation.png"/></p><h2 id="H4.Entropy-basedPruning"><span>4. Entropy-based Pruning</span></h2><p>&nbsp;In this section, we will discuss the pruning for back-off based n-gram language model.<br/><span class="box code">$ make m3_prune<br/> <span style="color: #666666; ">./</span>slmprune .<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.3gram .<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.3gm R 100000 1250000 1000000</span><br/>&nbsp;Let's look at the definition of Entropy, assume p<img src="/resources/icons/silk/cancel.gif" class="wikimodel-freestanding" alt="cancel"/>&nbsp;is the probability density function for random variable X, then the entropy of X is:<br/><img src="http://blogs.sun.com/yongsun/resource/entropy-equation.png" alt="http://blogs.sun.com/yongsun/resource/entropy-equation.png"/><br/>&nbsp;Note: the logarithm base is 2, and 0log 0 = 0.<br/>&nbsp;Entropy is used to measure the determinability of random events. The entropy value is larger, the determinability is lower. The last part of the above equation indicates that entropy is the expectation of log(1/p(X)). If p(X=xi) equals to 1/256, then log(1/p(xi))=log(256)=8, which means it requires 8 bits to encode the event xi. And H(p) is its expectation (weighted-average), i.e., the average information length.<br/>&nbsp;Let's look at the relative entropy (i.e., Kullback-Leibler distance):<br/><img src="http://blogs.sun.com/yongsun/resource/relative-entropy.png" alt="http://blogs.sun.com/yongsun/resource/relative-entropy.png"/><br/>&nbsp;It means if the distribution of random variable X is p<img src="/resources/icons/silk/cancel.gif" class="wikimodel-freestanding" alt="cancel"/>, while we use q<img src="/resources/icons/silk/cancel.gif" class="wikimodel-freestanding" alt="cancel"/>&nbsp;to encode X, the extra bits we are going to use.<br/>&nbsp;The equation to calculate conditional relative entropy is:<br/><img src="http://blogs.sun.com/yongsun/resource/conditional-relative-entropy.png" alt="http://blogs.sun.com/yongsun/resource/conditional-relative-entropy.png"/><br/>&nbsp;Note: for the proving of this equation, please refer to "<span class="wikiexternallink"><a href="http://www.amazon.com/exec/obidos/ASIN/0471062596/qid%3D1117706264/sr%3D11-1/ref%3Dsr%5F11%5F1/104-5677540-4720753">Elements of Information Theory</a></span>".<br/>&nbsp;Let's look at how to use relative entropy to prune back-off language model. The following analysis comes from "<span class="wikiexternallink"><a href="http://www.speech.sri.com/papers/darpa98-lm-pruning.ps.gz">Entropy-based Pruning of Backoff Language Models</a></span>".<br/>&nbsp;Recall the general form of a back-off model,<br/><span class="box code">&nbsp;Ps(Wi<span style="color: #666666; ">|</span>h) = Pd(Wi<span style="color: #666666; ">|</span>h)         <span style="color: #666666; ">~--</span> C(h,Wi) <span style="color: #666666; ">&gt;</span> 0<br/>&nbsp;           bow(h).Ps(Wi<span style="color: #666666; ">|</span>h<span style="color: #666666; ">'</span>) <span style="color: #666666; ">~--</span> C(h,Wi) <span style="color: #666666; ">==</span> 0</span><br/>&nbsp;The goal of pruning, is to remove some n-grams which have explicit estimation (i.e., C(h,Wi)&gt;0), to reduce the size of parameters, while minimizing the performance loss. (Note, after the pruning, the probabilities of left ones which have explicit estimations do not change).<br/>&nbsp;Pruning Steps:</p><ol><li>Select a threshold,</li><li>Calculate the relative entropy by pruning each n-gram individually,</li><li>Remove all N-grams that raise the relative entropy by less than the threshold, then re-calculate the back-off weights.</li></ol><p>&nbsp;Assume we removed (h, w) from the model, when we want to calculate p(w|h), it requires backed-off (or implicit) estimation. To guarantee the formality of the model, i.e., to make sure sum_wi p(wi|h) = 1, bow(h) must be re-calculated, named as bow'(h), so p'(w|h) = bow'(h).p(w|h'). While the meantime, all backed-off estimations involving h are impacted, we use notation BO(wi,h) to denote this case (it's actually the circumstances that C(h,wi) == 0). We could get:<br/><img src="http://blogs.sun.com/yongsun/resource/relative-entropy-for-pruning-1.png" alt="http://blogs.sun.com/yongsun/resource/relative-entropy-for-pruning-1.png"/><br/>&nbsp;Note, h and w are given and concrete. And besides (h, w), the probabilities of left n-grams which have explicit estimations do not change, so some parts of the summation are counteracted.<br/>&nbsp;Finally (please refer to the quoted paper for details), we could get:<br/><img src="http://blogs.sun.com/yongsun/resource/relative-entropy-for-pruning-2.png" alt="http://blogs.sun.com/yongsun/resource/relative-entropy-for-pruning-2.png"/><br/>&nbsp;In above equation, p(h={h1,h2...}) = p(h1)p(h2|h1)..., and we also know:<br/><img src="http://www.sitmo.com/latex/latex2png.php?eq=%5Csum_%7Bw_i:BO%28w_i,h%29%7D%20p%28w_i%7Ch%29%20=%201%20-%20%5Csum_%7Bw_i:%5Cneg%20BO%28w_i,h%29%7D%20p%28w_i%7Ch%29" alt="http://www.sitmo.com/latex/latex2png.php?eq=%5Csum_%7Bw_i:BO%28w_i,h%29%7D%20p%28w_i%7Ch%29%20=%201%20-%20%5Csum_%7Bw_i:%5Cneg%20BO%28w_i,h%29%7D%20p%28w_i%7Ch%29"/><br/>&nbsp;Next step is to calculate bow'(h):<br/><img src="http://blogs.sun.com/yongsun/resource/bow%28h%29%20and%20bow%27%28h%29.png" alt="http://blogs.sun.com/yongsun/resource/bow%28h%29%20and%20bow%27%28h%29.png"/><br/>&nbsp;To calculate bow'(h), is to drop the term for the pruned N-gram (w, h) from the summation in both numerator and denominator. Since bow(h) is known, if we got the numerator, then we could get the denominator, then add p(w|h) and p(w|h') separately. Then, we could get bow'(h).<br/>&nbsp;Let's look at the code:<br/><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmprune/slmprune.cpp">slmprune.cpp</a></span>:<br/><strong><br/><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmprune/slmprune.cpp#85">CSlmPruner::Prune</a></span>()</strong>:</p><blockquote><p>&nbsp;&nbsp;Call PrunLevel(lvl) from level[N] to level[1], to prune each level. After the pruning, call CalcBOW() to re-calculate the back-off weights for each node in level[0..N-1].</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmprune/slmprune.cpp#142">CSlmPruner::PruneLevel</a></span>(lvl)</strong>:</p><blockquote><p>&nbsp;&nbsp;sz[lvl] holds the node numbers in level[lvl], which include the pseudo tail, so the actually node number is sz[lvl]-1, assign it to n. cut[lvl] is the amount to be removed for this level. Allocate TNodeInfo[n] array, and assign to pbuf. Iterate each node in level[lvl], get its preceding nodes by a for loop, and put this n-gram to hw[0..lvl], keep the indices for each level to idx[0..lvl]. Figure out if this node has children ((pn+1)-&gt;child &gt; pn-&gt;child), if yes, this node could not be pruned. If no, call CalcDistance(lvl, idx, hw) to calculate the increased relative entropy by removing this node. Save the information to pbuf. Continue to the next node in level[lvl].</p></blockquote><p>&nbsp;After the iteration, perform a heap sorting to TNodeInfo array. Then iterate the top cut[lvl] elements in TNodeInfo array, set the probability in level[lvl][pinfo-&gt;idx] to 1.0. Then call CutLevel(), clean up the nodes whose probabilities are 1.0 from level[lvl], and change the child index of its parent node in level[lvl-1]. Assign the new size of level[lvl] to sz[lvl]. Clean up the allocated memory then return.</p><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmprune/slmprune.cpp#275">CSlmPruner::CalcDistance</a></span>(lvl, idx[], hw[0..lvl])</strong>:</p><blockquote><p>&nbsp;&nbsp;Firstly, get the bow(h) from its parent node, and save it in variable BOW. Then calculate p(h), p(h) = p(hw1).p(hw2|hw1)...p(hwlvl-1|hw1hw2...hwlvl-2), save it in variable PH. Then the probability on node level[lvl][idx[lvl]] is just p(w|h), save it to PHW. Call getPr(lvl-1, hw+2) to get the probability of p(w|h'), save it in variable PH_W.</p></blockquote><p>&nbsp;If cache_level is not lvl-1 (then is -1), or cache_idx is not idx[lvl-1] (then is -1), then assign the proper indices to cache_level and cache_idx separately, and initialize cache_PA and cache_PB to 1.0. Iterate its child nodes [parent-&gt;child, (parent+1)-&gt;child), get the probability on each child node (i.e., p(wi|h)), and subtracted from cache_PA; and set hw[lvl] with the word id on current child node, call getPr(lvl-1, hw+2) to get probability p_r (i.e., p(wi|h')), and subtracted from cache_PB. After iteration, PA = sum_{w_i:BO(w_i,h)} P(w_i|h), and PB = sum_{w_i:BO(w_i,h)} P(w_i|h'). Add p(w|h) and p(w|h') to PA and PB separately, then get the quotient of PA/PB, i.e., bow'(h), save it in variable _BOW.<br/>&nbsp;At last, follow the above equation to calculate D(p||p'), and return it.</p><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmprune/slmprune.cpp#236">CSlmPruner::CalcBOW</a></span>()，<span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmprune/slmprune.cpp#217">CalcNodeBow</a></span>(...)</strong>:</p><blockquote><p>&nbsp;&nbsp;It's similar with the <strong>CSlmBuilder::CalcBOW()</strong> and <strong>CalcNodeBow(...)</strong> in previous section. Not repeat here.</p></blockquote><h2 id="H5.Threadingthelanguagemodel"><span>5. Threading the language model</span></h2><p>Let's look at the last step, threading (or adding back-off indices) to the pruned language model.<br/><span class="box code">$ make m3_thread<br/> <span style="color: #666666; ">./</span>slmthread .<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.3gm .<span style="color: #666666; ">./</span>data<span style="color: #666666; ">/</span>lm_sc.t3g</span><br/>&nbsp;The goal of threading is to accelerate the searching in language model. Take trigram as an example, if we want to calculate the probability of sentence "ABCDE。", P(S) = P(A).P(B|A).P(C|AB).P(D|BC).P(E|CD).P(&lt;EOS&gt;|DE), and assume no back-off needed when evaluating all these conditional probabilities.<br/>&nbsp;First, we get P(A) from level[1] (unigram) via a binary search; and find B from A's children via a binary search, to get P(B|A); and then find C from B's children via another binary search, to get P(C|AB). The next step is to calculate P(D|BC). Then we need go back to unigram to find B, and then get C from B's children, then get P(D|BC), all these done by binary searches. Obviously, the performance is low. When we evaluating P(C|AB), if we could directly locate to (B, C) from node C, we could get the search much faster.<br/>&nbsp;We use (level, idx) to denote a node, the information on this node is described as (W, h', p, b, c):</p><ul><li>W：word id. The location of this node implies its history information.</li><li>h'：The back-off node, described as (level', idx').</li><li>p：p(W|h)</li><li>b：bow(h)</li><li>c：The start index of child node in next level.</li></ul><p>Certainly, there is no b and c on leaf node. Now, the back-off structure becomes a graph from a tree. Its basic operation is: on current history state hi(level,idx), by given an input word W, it transfer to another history state hj(level', idx'), and return P(W|h). The level' on hj, not always equals to level-1. E.g., C(ABC)&gt;0, but (B, C) is not seen in training, then the h' on this node is the C node on level[1]. If C is not seen either, h' is then the pseudo root (level[0][0]).<br/>&nbsp;Let's look at the following snippet,<br/><span class="box code">                                level<span style="color: #666666; ">+</span>1<br/>&nbsp;h (level,idx)    <span style="color: #666666; ">~-----------&gt;</span>   W1,p1,h<span style="color: #666666; ">'</span>1,[b,c]<br/>&nbsp;    h<span style="color: #666666; ">'</span>,bow       <span style="color: #666666; ">\</span>              ... ...<br/>&nbsp;                  <span style="color: #666666; ">\</span>             Wi,<span style="color: #008000; ">pi</span>,h<span style="color: #666666; ">'</span><span style="color: #008000; ">i</span>,[b,c]<br/>&nbsp;                   <span style="color: #666666; ">\</span>            ... ...<br/>&nbsp;                    <span style="color: #666666; ">~--------&gt;</span>   Wk,pk,h<span style="color: #666666; ">'</span>k,[b,c]</span><br/>&nbsp;Given an input word W. If W is one child of h, denoted as N (level+1, idx'), its p value is just P(W|h).<br/>&nbsp;    If N has children, then N is the new history node;<br/>&nbsp;    If not, the h' on N becomes the new history node.<br/>&nbsp;If W is not child of h, execute the same processing from h' on (level, idx), find the new history node, and times the probability with bow(h), return it as P(W|h). Note, it's a recursive process.<br/>&nbsp;Let's look at the code:<br/><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/thread/slmthread.cpp">&nbsp;slmthread.cpp</a></span>:<br/><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/thread/slmthread.cpp#124">&nbsp;CSIMSlmWithIteration::getIdString</a></span>(it, history)</strong>:</p><blockquote><p>&nbsp;The m_history member (std::vector&lt;int&gt;) holds the indices for each level, save the word ID on this node to passed in argument history. Method next() increase the last element in m_history (i.e., the index in current level), and call adjustIterator() to find the preceding nodes, save the indices to m_history.</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/thread/slmthread.cpp#110">&nbsp;CSIMSlmWithIteration::findBackOffState</a></span>(n, hw, bol, bon)</strong>:</p><blockquote><p>&nbsp;Find the back-off node (h') of a specified n-gram (held in hw[1..n]), and return its level and idx. Call findState() to get the idx of hw[2..n] on level[n-1], if the index is not less than 0 then this node (n-1, idx) does have child node, return the location of h'. Otherwise, call findState() to get the idx of hw[3..n] on level[n-2], ... If the loop reach hw[n], return the pseudo root.</p></blockquote><p>&nbsp;E.g., find the back-off node for trigram (A, B, C). Find out if (B, C) exists, if so, return (2, idx_BC). Otherwise, find out if (C) exists, if so return (1, idx_C). Otherwise, return (0, 0).</p><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/thread/slmthread.cpp#85">&nbsp;CSIMSlmWithIteration::findState</a></span>(n, hw)</strong>:</p><blockquote><p>&nbsp;Find the index of specified n-gram (held in hw[1..n]) on level[n]. If it does not exist, return -1.</p></blockquote><p>We also perform the compression for 32-bits floating numbers when threading. bow values are compressed to 14 bits, pr values are compressed to 16 bits. The basic idea is to count all bow (or pr) values, combine the clustering floating numbers, make the total number is under 1&lt;&lt;BITS_BOW (or 1&lt;&lt;BITS_PR); in the generated language model binary file, there are two floating tables, we need to search the table to get the original value. I'm not so clear about this algorithm, hopes the original author <span class="wikiexternallink"><a href="http://www.opensolaris.org/viewProfile.jspa?id=43520">Phill Zhang</a></span> to introduce more details.<br/>&nbsp;Now, we get the final language model -- lm_sc.t3g. You could use tslminfo to look at the data in plain text format:<br/><span class="box code">$ make m3_tslminfo<br/> <span style="color: #666666; ">./</span>tslminfo <span style="color: #666666; ">-</span>p <span style="color: #666666; ">-</span>v <span style="color: #666666; ">-</span>l .<span style="color: #666666; ">./</span>raw<span style="color: #666666; ">/</span>dict.utf8 .<span style="color: #666666; ">./</span>data<span style="color: #666666; ">/</span>lm_sc.t3g <span style="color: #666666; ">&gt;</span>.<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.t3g.arpa<br/>&nbsp;$ tail .<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.t3g.arpa<br/>&nbsp;点击 率 也   0.036363638937 (2,839922)<br/>&nbsp;点击 率 最高   0.081818044186 (2,840054)<br/>&nbsp;点击 率 的   0.096969485283 (2,840080)<br/>&nbsp;点击 率 达到   0.036363638937 (2,840122)<br/>&nbsp;点击 量 达   0.485714286566 (2,1132198)<br/>&nbsp;点击 鼠标 ，   0.400000005960 (1,1)<br/>&nbsp;点击 鼠标 左   0.309090882540 (2,1186378)<br/>&nbsp;率队 取得 <span style="color: #666666; ">&lt;</span>unknown<span style="color: #666666; ">&gt;</span>   0.479999989271 (2,366031)<br/>&nbsp;率队 在 <span style="color: #666666; ">&lt;</span>unknown<span style="color: #666666; ">&gt;</span>   0.130769222975 (2,431213)<br/>&nbsp;率队 打 了   0.479999989271 (2,642183)</span><br/>&nbsp;We could use <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slm.h">&nbsp;CThreadSlm</a></span> to access or use the language model. In next section, we will use <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmseg/slmseg.cpp">&nbsp;slmseg</a></span> as an example, to see how we construct the lattice and search by leveraging the generated language model.</p><h2 id="H6.Usingthegeneratedlanguagemodel"><span>6. Using the generated language model</span></h2><p>&nbsp;In previous step, we generated the threaded language model. The next question is how to use this model? Let's look at the header file of CThreadSlm class, <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slm.h">slm.h</a></span>, here are the public methods:</p><ol><li>load(): Load the language model to memory</li><li>free(): Release the memory allocated for the language model</li><li>isUseLogPr(): If the language model use log values for probabilities</li><li>transfer(history, wid, result): By given a word id wid, transfer from history state (history) to new state (result), and return P(wid|history).</li><li>transferNegLog(history, wid, result): Similar with above method, but returns -log(p(wid|history).</li><li>history_state_of(st): Get the h' of st, and return.</li><li>historify(st): Set st to its h'.</li><li>lastWordId(st): Return the last word id of state st. Assuming st is (lvl, idx), if lvl&gt;=N, then return m_Levels[N][idx]; if 0&lt;lvl&lt;N, return m_level[lvl][idx]; if level==0 and idx==0, return the word id on pseudo root (i.e., 0), if idx&gt;0 just return idx (we will discuss this situation when introducing <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/ime/src/ic_history.h">history cache</a></span>.</li></ol><p>&nbsp;Now, let's look at <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmseg/slmseg.cpp">slmseg</a></span> to see how to searching by leveraging CThreadSlm class.<br/><span class="box code">$ make slmids3<br/> <span style="color: #666666; ">./</span>slmseg <span style="color: #666666; ">-</span>d .<span style="color: #666666; ">./</span>raw<span style="color: #666666; ">/</span>dict.utf8 <span style="color: #666666; ">-</span>f bin <span style="color: #666666; ">-</span>s 10 <span style="color: #666666; ">-</span>m .<span style="color: #666666; ">./</span>data<span style="color: #666666; ">/</span>lm_sc.t3g .<span style="color: #666666; ">./</span>raw<span style="color: #666666; ">/</span>corpus.utf8 <span style="color: #666666; ">&gt;</span>.<span style="color: #666666; ">./</span>swap<span style="color: #666666; ">/</span>lm_sc.ids</span><br/>&nbsp;The source code of <span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmseg/slmseg.cpp">slmseg/slmseg.cpp</a></span>:</p><p><span class="box code">struct TLatticeWord {<br/>&nbsp;  int m_left;<br/>&nbsp;  int m_right;   <span style="color: #666666; ">//</span>[m_left, m_right) is the index range on lattice <span style="font-weight: bold; color: #008000; ">for</span> this word<br/>&nbsp;  int m_wordId;  <span style="color: #666666; ">//</span>word id<br/>&nbsp;};<br/>&nbsp;struct TLatticeStateValue{<br/>&nbsp;  double             m_pr;       <span style="color: #666666; ">//</span>the probability on this state node<br/>&nbsp;  TLatticeWord<span style="color: #666666; ">*</span>      mp_btword;  <span style="color: #666666; ">//</span>the back<span style="color: #666666; ">-</span>trace word, <span style="color: #008000; ">i</span>.e., the given word causing the transformation<br/>&nbsp;  CThreadSlm::TState m_btstate;  <span style="color: #666666; ">//</span>the back<span style="color: #666666; ">-</span>trace state, <span style="color: #008000; ">i</span>.e., where the current state comes from<br/>&nbsp;};<br/> <span style="color: #666666; ">/*</span> The mapping of SLM state node, and its Lattice state information <span style="color: #666666; ">*/</span><br/>&nbsp;typedef std::map<span style="color: #666666; ">&lt;</span>CThreadSlm::TState, TLatticeStateValue<span style="color: #666666; ">&gt;</span> TLatticeColumnStates;<br/> <span style="color: #666666; ">/*</span> represent a column of lattice <span style="color: #666666; ">*/</span><br/>&nbsp;struct TLatticeColumn {<br/>&nbsp;  TLatticeWordVec m_wordstarting;  <span style="color: #666666; ">//</span></span><span class="box code">The words starting from this column, these are actually the input words when expending this column</span><span class="box code">,<br/>&nbsp;                                   <span style="color: #666666; ">//</span>the newly transferred state node, located at lattice[word.m_right].<br/>&nbsp;  TLatticeColumnStates m_states;   <span style="color: #666666; ">//</span>the SLM state nodes and their corresponding Lattice states<br/>&nbsp;};</span> <strong><br/><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmseg/slmseg.cpp#329">processSingleFile</a></span>():</strong></p><blockquote><p>&nbsp;&nbsp;Read the corpus sentence by sentence. For each sentence, call buildLattice() to build the searching lattice, and call searchBest() to search on the lattice, and get the best segmentation by getBestPath(), and call output() to write out the best segmentation.</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmseg/slmseg.cpp#245">buildLattice</a></span>(sentence, lattice)</strong>:</p><blockquote><p>&nbsp;&nbsp;Set the SLM state on lattice[0] as pseudo root. Initialize i as 0, perform FMM for sntnc[i..n], get the word length -- len. And call getAmbiLen() to get the length of maximum length of crossing-ambiguities -- ambilen. If ambilen &lt;= len, then there is no crossing-ambiguities, then call insertLatticeWord() to insert ([i, i+len), Wid) to the word list of lattice[i]; set i=i+len, continue the loop. If there is crossing-ambiguities, call fullSegbuildLattice() to perform a full segmentation for sub-sentence sntnc[i..i+ambilen), for all segmented words (including all single-character word), assuming one's location is [left, right), insert it to lattice[left]; and set i=i+ambilen, continue the loop. After the iteration is done, add an end-of-sentence id (we use "。" for this id in following examples) at the end.</p></blockquote><p>&nbsp;Use the example in section 2,</p><blockquote><p> <img src="http://blogs.sun.com/yongsun/resource/slmseg_build_lattice.png" alt="http://blogs.sun.com/yongsun/resource/slmseg_build_lattice.png"/></p></blockquote><blockquote><p>&nbsp;&nbsp;Perform the FMM for this sample sentence, the first word we get is "发扬", and no ambiguity, so insert "发扬" to lattice[0]. Then i=2, continue the loop. The FMM result is "为人民", but the ambilen is 6, so we need perform full segmentation for sntnc[2..7]. Insert all possible segments on idx (2&lt;=idx&lt;7) to latttice[idx]. Then i=2+6=8, continue the loop. The FMM result is "的", and no ambiguity. Then i=9, the FMM result is "精神" and no ambiguity. After the loop is finished, add an end-of-sentence ID at the tail. We could see, there is no word on lattice[1], and the words on lattice[2] are "为", "为人", and "为人民". And so on...</p></blockquote><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmseg/slmseg.cpp#276">searchBest</a></span>(lattice)</strong>:</p><blockquote><p>&nbsp;&nbsp;Iterate the lattice from 0. For all lattice state nodes on lattcie[i], use the words starting from this lattice ([left, right), Wid) to expand, save the newly transferred state node h' (CThreadSlm::historify(his)) to lattice[word.m_right].m_states. Note, given a word D, two different state nodes (A, C) and (B, C) may result in the same h' (i.e., (C, D)), so we only need to keep the path who has bigger probability.</p></blockquote><p><img src="http://blogs.sun.com/yongsun/resource/slmseg_search_best.png" alt="http://blogs.sun.com/yongsun/resource/slmseg_search_best.png"/></p><blockquote><p>&nbsp;&nbsp;Let's start from lattice[0], we have set it as pseudo root (0, 0) in buildLatice() method. There is only one word on lattice[0], "发扬"; call CThreadSlm::trnasferNegLog((0,0), wid_of("发扬")), get the new SLM state node and the probability P("发扬"), save its h' (lvl=1, idx) and its lattice state information (probability and back-trace information) to lattice[2]. Then look at lattice[1], there is no state node to be expanded. Then going forward to lattice[2], there is one state node, and three words ("为", "为人", "为人民"), save the newly transferred three nodes to lattice[3], lattice[4] and lattice[5]. And so on...</p></blockquote><p>&nbsp;This is a dynamic programming problem, and what we used here is Viterbi Lattice algorithm.</p><p><strong><span class="wikiexternallink"><a href="http://src.opensolaris.org/source/xref/nv-g11n/inputmethod/sunpinyin/slm/src/slm/slmseg/slmseg.cpp#304">getBestPath</a></span>(lattice, segResult):</strong></p><blockquote><p>&nbsp;&nbsp;From end to start, back-trace the lattice, save the word id on best path to segResult. By reversing segResult, we got the best segmentation. For our example, it's the blue path on above figure.</p></blockquote><h2 id="H7.BuildLexiconTable"><span>7. Build Lexicon Table</span></h2><p>&nbsp;Since it's very Chinese specific, ignore this section</p>
</div>


    <div class="clearfloats"></div>
  </div>      <div id="xdocFooter">
  
                

       <div class="doc-tags" id="xdocTags">
        Tags:
        </div>
  
  <div id="xdocAuthors">
    <div class="xdocCreation">       Created by admin on 2009/10/26 12:14<br/>
          </div>
    <div class="xdocLastModification">       Last modified by admin on 2009/10/26 12:14
    </div>
  </div>
</div>
<div id="xwikidata" class="layoutsubsection">
        </div>  
    </div>      </div><div id="leftPanels" class="panels left">
                  <div class="panel expanded OSNav">
<h1 class="xwikipaneltitle" onclick="XWiki.togglePanelVisibility(this.parentNode, 'XWiki.XWikiGuest_Panels.OSNav');">Collectives</h1>
<div class="xwikipanelcontents">
<div id="xwikinavcontainer">
<span class="wikilink"><a href="/bin/view/Main/communities">Community Groups</a></span><br/>
<span class="wikilink"><a href="/bin/view/Main/projects">Projects</a></span><br/>
<span class="wikilink"><a href="/bin/view/Main/usergroups">User Groups</a></span>
</div><p/>
<script type="text/javascript">
document.observe('xwiki:dom:loaded', function() {
var obj = {div:'xwikinav',no:$count,height:250};
var acc = createAccordion(obj);
});
</script>
</div>
</div>
                        <div class="panel expanded OSDocs">
<h1 class="xwikipaneltitle" onclick="XWiki.togglePanelVisibility(this.parentNode, 'XWiki.XWikiGuest_Panels.OSDocs');">Project input-method Pages</h1>
<div class="xwikipanelcontents">
<ul class="star">
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/documents">Documents</a></span><ul class="star">
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/building_ibus">Build and use iBus</a></span></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/building_iiimf">Build IIIMF</a></span></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/building_scim">Build SCIM</a></span></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/building_sunpinyin">Build SunPinyin</a></span></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/building_uim">Build UIM</a></span></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/howtos">Howtos</a></span></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_ime">SunPinyin代码导读&#45;IME部分</a></span></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm">SunPinyin代码导读&#45;SLM部分</a></span></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/sunpinyin_code_tour_slm_en">SunPinyin Code Tour &#45; SLM</a></span></li>
</ul></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/files">Files</a></span></li>
<li><span class="wikilink"><a href="/bin/view/Project+input%2Dmethod/repository">Repository</a></span></li>
</ul>
                              </div>
</div>
      </div>

  </div>
<div class="clearfloats"></div>
  </div></div><div id="footerglobal" class="layoutsection">
<div class="minwidth"></div>
<hr/>
        <div id="xwikiplatformversion">XWiki Enterprise 2.7.1.34853 - <a onclick="openURL('http://enterprise.xwiki.org/xwiki/bin/view/Main/Documentation', '_blank'); return false;" href="http://www.xwiki.org/xwiki/bin/view/Main/Documentation">Documentation</a></div>
<br/>
  
      <div id="footer">
    <p>
                <a href="https://markebrooks.github.io/bin/view/Main/tou/">Terms of Use</a>
                |
                <a href="http://www.oracle.com/html/privacy.html">Privacy</a>
                |
                <a href="https://markebrooks.github.io/bin/view/Main/trademark/">Trademarks</a>
                |
                <a href="https://markebrooks.github.io/bin/view/Main/copyrights/">Copyright Policy</a>
                |
                <a href="https://markebrooks.github.io/bin/view/Main/site_guidelines/">Site Guidelines</a>
                |
                <a href="https://markebrooks.github.io/bin/view/Main/site-map/">Site Map</a>
                |
                <a href="https://markebrooks.github.io/bin/view/Main/help/">Help</a>
                <br/>Your use of this web site or any of its content or software indicates your agreement to be bound by these Terms of Use.<br/>
                &copy; 2012, Oracle Corporation and/or its affiliates.<br/><img src="https://markebrooks.github.io:443/static/images/logo_oracle_footer.gif" alt="Oracle Logo"/>
            </p>
        </div>

  
</div>

</div></div></body>
</html>
